{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Epixxs/machine-learning/blob/main/exercises/spam-classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "68304db3",
      "metadata": {
        "id": "68304db3",
        "outputId": "acc8879d-e946-43df-f8cd-050104745df5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stemming\n",
            "  Downloading stemming-1.0.1.zip (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: stemming\n",
            "  Building wheel for stemming (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stemming: filename=stemming-1.0.1-py3-none-any.whl size=11123 sha256=03ff8ffc079bfa893436e61d9142b7d2939bdac4612353430fef0c06e0a5590f\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/d4/73/028ca44cd75949ad81250dd3ecea7e4c61b97672587b65ef35\n",
            "Successfully built stemming\n",
            "Installing collected packages: stemming\n",
            "Successfully installed stemming-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install stemming\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "from sklearn import svm\n",
        "import re\n",
        "from stemming.porter2 import stem\n",
        "import nltk, nltk.stem.porter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "407c2550",
      "metadata": {
        "id": "407c2550",
        "outputId": "5566cdfd-9bd1-438a-a220-4a00bcccee94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: The file 'data/spamSample1.txt' was not found.\n"
          ]
        }
      ],
      "source": [
        "file_path = 'data/spamSample1.txt'\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            print(line.strip())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{file_path}' was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63d72615",
      "metadata": {
        "id": "63d72615",
        "outputId": "63e1d0cd-9f80-4320-d0f8-7f05aaaac9d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:11: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:12: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:11: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:12: SyntaxWarning: invalid escape sequence '\\s'\n",
            "C:\\Users\\Sakshan Sharma\\AppData\\Local\\Temp\\ipykernel_15220\\172533917.py:11: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  email = re.sub('(http|https)://[^\\s]*', 'httpaddr',email)\n",
            "C:\\Users\\Sakshan Sharma\\AppData\\Local\\Temp\\ipykernel_15220\\172533917.py:12: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  email = re.sub('[^\\s]+@[^\\s]+', 'emailaddr', email)\n"
          ]
        }
      ],
      "source": [
        "def preProcess  ( email ):\n",
        "    \"\"\"\n",
        "    Function to do some pre processing (simplification of e-mails).\n",
        "    Comments throughout implementation describe what it does.\n",
        "    Input = raw e-mail\n",
        "    Output = processed (simplified) email\n",
        "    \"\"\"\n",
        "    email = email.lower()\n",
        "    email = re.sub('<[^<>]>', ' ',email)\n",
        "    email = re.sub('[0-9]+', 'number', email)\n",
        "    email = re.sub('(http|https)://[^\\s]*', 'httpaddr',email)\n",
        "    email = re.sub('[^\\s]+@[^\\s]+', 'emailaddr', email)\n",
        "    email = re.sub('[$]+', 'dollar', email)\n",
        "    return email\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "63e45c0f",
      "metadata": {
        "id": "63e45c0f",
        "outputId": "d59cb52e-e615-4048-f812-6b2ef2106356",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:8: SyntaxWarning: invalid escape sequence '\\@'\n",
            "<>:8: SyntaxWarning: invalid escape sequence '\\@'\n",
            "/tmp/ipython-input-644076407.py:8: SyntaxWarning: invalid escape sequence '\\@'\n",
            "  tokens = re.split('[\\@\\$\\/\\#\\.\\-\\:\\&\\*\\+\\=\\[\\]\\?\\!\\(\\)\\{\\}\\,\\'\\\"\\>\\_\\<\\_\\<\\;\\%]', email)\n"
          ]
        }
      ],
      "source": [
        "def email2TokenList( raw_email ):\n",
        "    \"\"\"\n",
        "    Function that takes in preprocessed (simplified) email, tokenizes it,\n",
        "    stems each word, and returns an (ordered) list of tokens in the e-mail\n",
        "    \"\"\"\n",
        "    stemmer = nltk.stem.porter.PorterStemmer()\n",
        "    email = preProcess( raw_email )\n",
        "    tokens = re.split('[\\@\\$\\/\\#\\.\\-\\:\\&\\*\\+\\=\\[\\]\\?\\!\\(\\)\\{\\}\\,\\'\\\"\\>\\_\\<\\_\\<\\;\\%]', email)\n",
        "    tokenlist = []\n",
        "    for token in tokens:\n",
        "        token = re.sub('[^a-zA-Z0-9]','',token)\n",
        "        stemmed = stemmer.stem( token )\n",
        "        if not len(token): continue\n",
        "        tokenlist.append(stemmed)\n",
        "    return tokenlist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2b611e73",
      "metadata": {
        "id": "2b611e73"
      },
      "outputs": [],
      "source": [
        "def getVocabDict(reverse=False):\n",
        "    \"\"\"\n",
        "    Function to read in the supplied vocab list text file into a dictionary.\n",
        "    I'll use this for now, but since I'm using a slightly different stemmer,\n",
        "    I'd like to generate this list myself from some sort of data set...\n",
        "    Dictionary key is the stemmed word, value is the index in the text file\n",
        "    If \"reverse\", the keys and values are switched.\n",
        "    \"\"\"\n",
        "    vocab_dict = {}\n",
        "    with open(\"data/vocab.txt\") as f:\n",
        "      for line in f:\n",
        "        (val, key) = line.split()\n",
        "        if not reverse:\n",
        "          vocab_dict[key] = int(val)\n",
        "        else:\n",
        "          vocab_dict[int(val)] = key\n",
        "    return vocab_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def email2VocabIndices( raw_email, vocab_dict ):\n",
        "    \"\"\"\n",
        "    Function that takes in a raw email and returns a list of indices corresponding\n",
        "    to the location in vocab_dict for each stemmed word in the email.\n",
        "    \"\"\"\n",
        "    tokenlist = email2TokenList( raw_email )\n",
        "    index_list = [ vocab_dict[token] for token in tokenlist if token in vocab_dict ]\n",
        "    return index_list"
      ],
      "metadata": {
        "id": "94aYpOFT6zWX"
      },
      "id": "94aYpOFT6zWX",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def email2FeatureVector( raw_email, vocab_dict ):\n",
        "    \"\"\"\n",
        "    Function that takes as input a raw email, and returns a vector of shape\n",
        "    (n,1) where n is the size of the vocab_dict.\n",
        "    The first element in this vector is 1 if the vocab word with index == 1\n",
        "    is in the raw_email, 0 otherwise.\n",
        "    \"\"\"\n",
        "    n = len(vocab_dict)\n",
        "    result = np.zeros((n,1))\n",
        "    vocab_indices = email2VocabIndices( email_contents, vocab_dict )\n",
        "    for idx in vocab_indices:\n",
        "        result[idx] = 1\n",
        "    return result"
      ],
      "metadata": {
        "id": "_vZeItyR63Qq"
      },
      "id": "_vZeItyR63Qq",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_dict = getVocabDict()\n",
        "email_contents = open('data/emailSample1.txt', 'r').read()\n",
        "test_fv = email2FeatureVector(email_contents, vocab_dict)\n",
        "print(\"Length of feature vector is %d\" % len(test_fv))\n",
        "print(\"Number of non-zero entries is: %d\" % sum(test_fv==1))"
      ],
      "metadata": {
        "id": "EplTPkDW8AsG",
        "outputId": "d3a3345d-b449-44c3-9d0c-27c902b2870f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "id": "EplTPkDW8AsG",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/vocab.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4062975284.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocab_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetVocabDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0memail_contents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/emailSample1.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_fv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memail2FeatureVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memail_contents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Length of feature vector is %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_fv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of non-zero entries is: %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_fv\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3097919438.py\u001b[0m in \u001b[0;36mgetVocabDict\u001b[0;34m(reverse)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[1;32m      9\u001b[0m     \u001b[0mvocab_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/vocab.txt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/vocab.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "22oTjc7L9R1j"
      },
      "id": "22oTjc7L9R1j",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}