{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Epixxs/machine-learning/blob/main/exercises/spam-classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68304db3",
      "metadata": {
        "id": "68304db3"
      },
      "outputs": [],
      "source": [
        "!pip install stemming\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "from sklearn import svm\n",
        "import re\n",
        "from stemming.porter2 import stem\n",
        "import nltk, nltk.stem.porter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "407c2550",
      "metadata": {
        "id": "407c2550"
      },
      "outputs": [],
      "source": [
        "file_path = 'data/spamSample1.txt'\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            print(line.strip())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{file_path}' was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63d72615",
      "metadata": {
        "id": "63d72615"
      },
      "outputs": [],
      "source": [
        "def preProcess  ( email ):\n",
        "    \"\"\"\n",
        "    Function to do some pre processing (simplification of e-mails).\n",
        "    Comments throughout implementation describe what it does.\n",
        "    Input = raw e-mail\n",
        "    Output = processed (simplified) email\n",
        "    \"\"\"\n",
        "    email = email.lower()\n",
        "    email = re.sub('<[^<>]>', ' ',email)\n",
        "    email = re.sub('[0-9]+', 'number', email)\n",
        "    email = re.sub('(http|https)://[^\\s]*', 'httpaddr',email)\n",
        "    email = re.sub('[^\\s]+@[^\\s]+', 'emailaddr', email)\n",
        "    email = re.sub('[$]+', 'dollar', email)\n",
        "    return email\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63e45c0f",
      "metadata": {
        "id": "63e45c0f"
      },
      "outputs": [],
      "source": [
        "def email2TokenList( raw_email ):\n",
        "    \"\"\"\n",
        "    Function that takes in preprocessed (simplified) email, tokenizes it,\n",
        "    stems each word, and returns an (ordered) list of tokens in the e-mail\n",
        "    \"\"\"\n",
        "    stemmer = nltk.stem.porter.PorterStemmer()\n",
        "    email = preProcess( raw_email )\n",
        "    tokens = re.split('[\\@\\$\\/\\#\\.\\-\\:\\&\\*\\+\\=\\[\\]\\?\\!\\(\\)\\{\\}\\,\\'\\\"\\>\\_\\<\\_\\<\\;\\%]', email)\n",
        "    tokenlist = []\n",
        "    for token in tokens:\n",
        "        token = re.sub('[^a-zA-Z0-9]','',token)\n",
        "        stemmed = stemmer.stem( token )\n",
        "        if not len(token): continue\n",
        "        tokenlist.append(stemmed)\n",
        "    return tokenlist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b611e73",
      "metadata": {
        "id": "2b611e73"
      },
      "outputs": [],
      "source": [
        "def getVocabDict(reverse=False):\n",
        "    \"\"\"\n",
        "    Function to read in the supplied vocab list text file into a dictionary.\n",
        "    I'll use this for now, but since I'm using a slightly different stemmer,\n",
        "    I'd like to generate this list myself from some sort of data set...\n",
        "    Dictionary key is the stemmed word, value is the index in the text file\n",
        "    If \"reverse\", the keys and values are switched.\n",
        "    \"\"\"\n",
        "    vocab_dict = {}\n",
        "    with open(\"data/vocab.txt\") as f:\n",
        "      for line in f:\n",
        "        (val, key) = line.split()\n",
        "        if not reverse:\n",
        "          vocab_dict[key] = int(val)\n",
        "        else:\n",
        "          vocab_dict[int(val)] = key\n",
        "    return vocab_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def email2VocabIndices( raw_email, vocab_dict ):\n",
        "    \"\"\"\n",
        "    Function that takes in a raw email and returns a list of indices corresponding\n",
        "    to the location in vocab_dict for each stemmed word in the email.\n",
        "    \"\"\"\n",
        "    tokenlist = email2TokenList( raw_email )\n",
        "    index_list = [ vocab_dict[token] for token in tokenlist if token in vocab_dict ]\n",
        "    return index_list"
      ],
      "metadata": {
        "id": "94aYpOFT6zWX"
      },
      "id": "94aYpOFT6zWX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def email2FeatureVector( raw_email, vocab_dict ):\n",
        "    \"\"\"\n",
        "    Function that takes as input a raw email, and returns a vector of shape\n",
        "    (n,1) where n is the size of the vocab_dict.\n",
        "    The first element in this vector is 1 if the vocab word with index == 1\n",
        "    is in the raw_email, 0 otherwise.\n",
        "    \"\"\"\n",
        "    n = len(vocab_dict)\n",
        "    result = np.zeros((n,1))\n",
        "    vocab_indices = email2VocabIndices( email_contents, vocab_dict )\n",
        "    for idx in vocab_indices:\n",
        "        result[idx] = 1\n",
        "    return result"
      ],
      "metadata": {
        "id": "_vZeItyR63Qq"
      },
      "id": "_vZeItyR63Qq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_dict = getVocabDict()\n",
        "email_contents = open('data/emailSample1.txt', 'r').read()\n",
        "test_fv = email2FeatureVector(email_contents, vocab_dict)\n",
        "print(\"Length of feature vector is %d\" % len(test_fv))\n",
        "print(\"Number of non-zero entries is: %d\" % sum(test_fv==1))"
      ],
      "metadata": {
        "id": "EplTPkDW8AsG"
      },
      "id": "EplTPkDW8AsG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "22oTjc7L9R1j"
      },
      "id": "22oTjc7L9R1j",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}